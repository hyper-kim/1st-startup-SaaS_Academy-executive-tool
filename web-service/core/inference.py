import os
import glob
import torch
import re
import json
from django.conf import settings
from PIL import Image
from transformers import DonutProcessor, VisionEncoderDecoderModel
from pathlib import Path

# ì „ì—­ ë³€ìˆ˜ (Lazy Loadingìš©)
model = None
processor = None
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def load_model_lazy():
    """
    ìµœì´ˆ ìš”ì²­ì´ ë“¤ì–´ì™”ì„ ë•Œ ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤.
    """
    global model, processor
    
    if model is not None:
        return

    print("ğŸ’¤ ì ìë˜ AI ëª¨ë¸ì„ ê¹¨ìš°ëŠ” ì¤‘... (ì²« ë¡œë”©)")

    # 1. ê²½ë¡œ íƒìƒ‰ (web-service ìƒìœ„ -> ai-engine -> result)
    WEB_SERVICE_DIR = Path(settings.BASE_DIR)
    PROJECT_ROOT = WEB_SERVICE_DIR.parent
    AI_RESULT_DIR = PROJECT_ROOT / 'ai-engine' / 'result'
    
    print(f"ğŸ“ ê²½ë¡œ íƒìƒ‰ ìœ„ì¹˜: {AI_RESULT_DIR}")
    
    # 2. ì²´í¬í¬ì¸íŠ¸ í´ë” ìë™ ì°¾ê¸°
    checkpoints = glob.glob(os.path.join(str(AI_RESULT_DIR), "checkpoint-*"))
    
    if len(checkpoints) > 0:
        checkpoints.sort(key=lambda x: int(x.split('-')[-1]))
        MODEL_DIR = checkpoints[-1]
    else:
        MODEL_DIR = str(AI_RESULT_DIR)

    print(f"ğŸ”¥ ìµœì¢… AI ëª¨ë¸ ê²½ë¡œ: {MODEL_DIR}")

    try:
        # ---------------------------------------------------------
        # [í•µì‹¬ ìˆ˜ì •] í”„ë¡œì„¸ì„œì™€ ëª¨ë¸ ë¡œë”© ë¶„ë¦¬
        # ---------------------------------------------------------
        
        # 1. í”„ë¡œì„¸ì„œëŠ” 'ì›ë³¸ ë² ì´ìŠ¤ ëª¨ë¸'ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì„¤ì • íŒŒì¼ ëˆ„ë½ ë°©ì§€)
        #    ë§Œì•½ ì²´í¬í¬ì¸íŠ¸ì— íŒŒì¼ì´ ë‹¤ ìˆë‹¤ë©´ MODEL_DIRì—ì„œ ì½ê² ì§€ë§Œ, ì—†ìœ¼ë©´ ì›ë³¸ì—ì„œ ì½ìŠµë‹ˆë‹¤.
        try:
            processor = DonutProcessor.from_pretrained(MODEL_DIR)
        except OSError:
            print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ì— í”„ë¡œì„¸ì„œ ì„¤ì •ì´ ì—†ì–´ 'naver-clova-ix/donut-base'ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.")
            processor = DonutProcessor.from_pretrained("naver-clova-ix/donut-base")
            
            # â˜… ì¤‘ìš”: í•™ìŠµ ë•Œ ì¶”ê°€í–ˆë˜ íŠ¹ìˆ˜ í† í°ì„ ë˜‘ê°™ì´ ì¶”ê°€í•´ì¤˜ì•¼ í•¨
            processor.tokenizer.add_tokens(["<s_receipt>", "</s_receipt>"])

        # 2. ëª¨ë¸ì€ 'í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸'ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR)
        
        # í† í° í¬ê¸° ë§ì¶”ê¸° (ëª¨ë¸ì€ ì´ë¯¸ ëŠ˜ì–´ë‚˜ìˆê³ , í”„ë¡œì„¸ì„œë„ ë°©ê¸ˆ ëŠ˜ë ¸ìœ¼ë¯€ë¡œ ë§¤ì¹­ë¨)
        model.to(device)
        model.eval()
        
        print(f"âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (Device: {device})")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        model = None
        raise e

def run_inference(image_input):
    """
    views.pyì—ì„œ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    if model is None:
        try:
            load_model_lazy()
        except Exception as e:
            return {"status": "error", "message": f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}"}

    try:
        # 1. ì´ë¯¸ì§€ í¬ë§· í†µì¼
        if image_input.mode != "RGB":
            image_input = image_input.convert("RGB")

        # 2. ì „ì²˜ë¦¬
        pixel_values = processor(image_input, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(device)

        # 3. í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        task_prompt = "<s_receipt>"
        decoder_input_ids = processor.tokenizer(
            task_prompt, add_special_tokens=False, return_tensors="pt"
        ).input_ids.to(device)

        # 4. ìƒì„± (Inference)
        with torch.no_grad():
            outputs = model.generate(
                pixel_values,
                decoder_input_ids=decoder_input_ids,
                max_length=768,
                early_stopping=True,
                pad_token_id=processor.tokenizer.pad_token_id,
                eos_token_id=processor.tokenizer.eos_token_id,
                use_cache=True,
                
                # [ìˆ˜ì •ëœ ë¶€ë¶„] ----------------------------------
                num_beams=4,          # 1 -> 4 (ë” ì—¬ëŸ¬ ê²½ìš°ì˜ ìˆ˜ë¥¼ íƒìƒ‰í•˜ì—¬ ì •í™•ë„ í–¥ìƒ)
                repetition_penalty=1.2, # ë°˜ë³µí•´ì„œ ë§í•˜ë©´ íŒ¨ë„í‹° ë¶€ì—¬ (ì•µë¬´ìƒˆ ë°©ì§€)
                no_repeat_ngram_size=3, # 3ë‹¨ì–´ ì´ìƒ ë˜‘ê°™ì´ ë°˜ë³µ ê¸ˆì§€
                # -----------------------------------------------
                
                bad_words_ids=[[processor.tokenizer.unk_token_id]],
                return_dict_in_generate=True,
            )

        # 5. í›„ì²˜ë¦¬
        sequence = processor.batch_decode(outputs.sequences)[0]
        sequence = sequence.replace(processor.tokenizer.eos_token, "").replace(processor.tokenizer.pad_token, "")
        sequence = re.sub(r"<.*?>", "", sequence, count=1).strip()
        
        print(f"ğŸ¤– AI ë¶„ì„ ê²°ê³¼: {sequence}")

        try:
            json_output = processor.token2json(sequence)
            return {"status": "success", "result": json_output}
        except:
            return {"status": "partial_success", "result": {"text_content": sequence}}

    except Exception as e:
        return {"status": "error", "message": str(e)}