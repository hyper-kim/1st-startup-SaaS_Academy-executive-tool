import torch
import re
import json
from PIL import Image
from transformers import DonutProcessor, VisionEncoderDecoderModel

# -----------------------------------------------------------------------------
# â˜… [ì„¤ì •] ë³¸ì¸ì˜ Hugging Face ëª¨ë¸ IDë¡œ ë°”ê¿”ì£¼ì„¸ìš”
# í˜•ì‹: "ì‚¬ìš©ìì•„ì´ë””/ëª¨ë¸ëª…"
# ì˜ˆì‹œ: "hyper-kim/saas-receipt-model"
# -----------------------------------------------------------------------------
MODEL_ID = "HYPER-KJY/academy-receipt-model"

# ì „ì—­ ë³€ìˆ˜
model = None
processor = None
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def load_model_lazy():
    """
    ìµœì´ˆ ìš”ì²­ ì‹œ Hugging Face Hubì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ/ë¡œë“œí•©ë‹ˆë‹¤.
    """
    global model, processor
    
    if model is not None:
        return

    print(f"ğŸ’¤ Hugging Face Hubì—ì„œ ëª¨ë¸ì„ ì°¾ì•„ì˜¤ëŠ” ì¤‘... (ID: {MODEL_ID})")

    try:
        # ---------------------------------------------------------
        # Hugging Face Hub ìë™ ë¡œë“œ (ì¸í„°ë„· ì—°ê²° í•„ìˆ˜)
        # ---------------------------------------------------------
        # ë§Œì•½ ë¹„ê³µê°œ(Private) ëª¨ë¸ì´ë¼ë©´, í„°ë¯¸ë„ì—ì„œ 'huggingface-cli login'ì„ í–ˆê±°ë‚˜
        # token="hf_..." ì¸ìë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
        
        # 1. í”„ë¡œì„¸ì„œ ë¡œë“œ
        try:
            processor = DonutProcessor.from_pretrained(MODEL_ID)
        except OSError:
            # í˜¹ì‹œë‚˜ ì„¤ì • íŒŒì¼ì´ ê¼¬ì˜€ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜
            print("âš ï¸ ëª¨ë¸ ì €ì¥ì†Œì— í”„ë¡œì„¸ì„œ ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’(donut-base)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            processor = DonutProcessor.from_pretrained("naver-clova-ix/donut-base")
            processor.tokenizer.add_tokens(["<s_receipt>", "</s_receipt>"])

        # 2. ëª¨ë¸ ë¡œë“œ
        model = VisionEncoderDecoderModel.from_pretrained(MODEL_ID)
        
        # í† í° í¬ê¸° ë§ì¶¤
        model.decoder.resize_token_embeddings(len(processor.tokenizer))
        
        model.to(device)
        model.eval()
        print(f"âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (Source: Hugging Face Hub)")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        model = None
        raise e

def run_inference(image_input):
    """
    views.pyì—ì„œ í˜¸ì¶œí•˜ëŠ” ì¶”ë¡  í•¨ìˆ˜
    """
    if model is None:
        try:
            load_model_lazy()
        except Exception as e:
            return {"status": "error", "message": f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}"}

    try:
        # 1. ì´ë¯¸ì§€ í¬ë§· í†µì¼
        if image_input.mode != "RGB":
            image_input = image_input.convert("RGB")

        # 2. ì „ì²˜ë¦¬
        pixel_values = processor(image_input, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(device)

        # 3. í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        task_prompt = "<s_receipt>"
        decoder_input_ids = processor.tokenizer(
            task_prompt, add_special_tokens=False, return_tensors="pt"
        ).input_ids.to(device)

        # 4. ìƒì„± (Inference) - í’ˆì§ˆ ì˜µì…˜ ì ìš©
        with torch.no_grad():
            outputs = model.generate(
                pixel_values,
                decoder_input_ids=decoder_input_ids,
                max_length=768,
                early_stopping=True,
                pad_token_id=processor.tokenizer.pad_token_id,
                eos_token_id=processor.tokenizer.eos_token_id,
                use_cache=True,
                # ì•µë¬´ìƒˆ ë°©ì§€ ì˜µì…˜
                num_beams=4,
                repetition_penalty=1.2,
                no_repeat_ngram_size=3,
                
                bad_words_ids=[[processor.tokenizer.unk_token_id]],
                return_dict_in_generate=True,
            )

        # 5. í›„ì²˜ë¦¬
        sequence = processor.batch_decode(outputs.sequences)[0]
        sequence = sequence.replace(processor.tokenizer.eos_token, "").replace(processor.tokenizer.pad_token, "")
        sequence = re.sub(r"<.*?>", "", sequence, count=1).strip()
        
        print(f"ğŸ¤– AI ë¶„ì„ ê²°ê³¼(Raw): {sequence}")

        # 6. JSON íŒŒì‹±
        try:
            json_output = processor.token2json(sequence)
            return {"status": "success", "result": json_output}
        except Exception as json_err:
            return {"status": "partial_success", "result": {"text_content": sequence}}

    except Exception as e:
        return {"status": "error", "message": str(e)}