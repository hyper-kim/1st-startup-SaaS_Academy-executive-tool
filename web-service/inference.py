import os
import glob
import torch
from django.conf import settings
from PIL import Image
from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor

# 1. ê²½ë¡œ ì„¤ì • (result í´ë”)
RESULT_DIR = os.path.join(settings.BASE_DIR, '..', 'ai-engine', 'result')
RESULT_DIR = os.path.abspath(RESULT_DIR)

checkpoints = glob.glob(os.path.join(RESULT_DIR,"checkpoint-*"))

if len(checkpoints) > 0:
    checkpoints.sort()
    MODEL_DIR = checkpoints[-1]
    print(f"ğŸ”„ ìë™ ê°ì§€ëœ ìµœì‹  ëª¨ë¸: {os.path.basename(MODEL_DIR)}")
else:
    MODEL_DIR = RESULT_DIR
    print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ í´ë” ì—†ìŒ. ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: {MODEL_DIR}")
    
print(f"ğŸ”¥ VisionEncoderDecoder ëª¨ë¸ ë¡œë”© ê²½ë¡œ: {MODEL_DIR}")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

try:
    # 2. ëª¨ë¸ ë¡œë“œ (VisionEncoderDecoderModel)
    model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR)
    model.to(device)
    model.eval()

    # 3. ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ(Feature Extractor) ë¡œë“œ
    # (ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì´ ì´í•´í•˜ëŠ” ìˆ«ìë¡œ ë³€í™˜)
    feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_DIR)

    # 4. í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì € ë¡œë“œ (ê²°ê³¼ ìˆ«ìë¥¼ ë‹¤ì‹œ ê¸€ìë¡œ ë³€í™˜)
    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
    
    print(f"âœ… ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ ë¡œë”© ì„±ê³µ! (Device: {device})")

except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë”© ëŒ€ì‹¤íŒ¨: {e}")
    model = None
    feature_extractor = None
    tokenizer = None

def run_inference(image_input):
    """
    image_input: PIL Image ê°ì²´
    """
    if model is None:
        return {"error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    try:
        # 
        # 1. ì´ë¯¸ì§€ê°€ ë§Œì•½ RGBê°€ ì•„ë‹ˆë¼ë©´ ë³€í™˜ (ì•ˆì „ì¥ì¹˜)
        if image_input.mode != "RGB":
            image_input = image_input.convert("RGB")

        # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        pixel_values = feature_extractor(images=image_input, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(device)

        # 3. í…ìŠ¤íŠ¸ ìƒì„± (Generate)
        with torch.no_grad():
            output_ids = model.generate(
                pixel_values,
                max_length=128,      # ìƒì„±í•  ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´
                num_beams=4,         # ë¹” ì„œì¹˜ (ì •í™•ë„ í–¥ìƒ)
                early_stopping=True
            )

        # 4. ê²°ê³¼ ë””ì½”ë”© (ìˆ«ì -> í…ìŠ¤íŠ¸)
        generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)

        return {
            "status": "success",
            "result": generated_text
        }

    except Exception as e:
        return {"status": "error", "message": str(e)}